{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import requests\n",
    "import nltk\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in template questions,answers and memory\n",
    "template_q = pd.read_csv('data/likes_question_templates.csv')\n",
    "retrieval_q = pd.read_csv('data/questions_templates.csv')\n",
    "template_a = pd.read_csv('data/answer_templates.csv')\n",
    "retrieval_a = pd.read_csv('data/answer_templates_2.csv')\n",
    "like_memory = pd.read_csv('data/sentiment_memory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some fruits are listed under \"Food\" topic, so the line below is temporary remove solution\n",
    "like_memory = like_memory.drop_duplicates(subset='subject', keep=\"last\")\n",
    "#Assign random sentiment to every noun item in memory\n",
    "temp = np.random.random(len(like_memory))\n",
    "like_memory['sentiment'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'animal': 0.5266773475979342, 'food': 0.638869731751168, 'hobby': 0.4588529456011475, 'TV show': 0.5372296807329312, 'fruit': 0.49724013777262815, 'music': 0.36348344566163315, 'dessert': 0.4949504716896939, 'sport': 0.43641777358113737, 'genre': 0.31708426163962333, 'interest': 0.3105392522365218, 'movie': 0.5274147535813526, 'book': 0.49596100915202107, 'color': 0.5680000716760845}\n"
     ]
    }
   ],
   "source": [
    "#def calculate_topic_sent(): \n",
    "#Calculate topic average sentiment (not very useful considering random function mean 0.5)\n",
    "topic_sent = {}\n",
    "memory_topics = set(like_memory.topic)\n",
    "for topic in memory_topics:\n",
    "    topic_list = like_memory.loc[like_memory['topic'] == topic]\n",
    "    count = 0\n",
    "    divisor = len(topic_list)\n",
    "    for i in range(divisor):\n",
    "        count = count + topic_list.sentiment.iloc[i]\n",
    "    topic_sent[topic] = count/divisor\n",
    "print(topic_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'animal': ['tiger', 'sheep', 'bear', 'pig', 'horse'], 'food': ['eggs', 'rice', 'noodles', 'gyro', 'pasta'], 'hobby': ['scuba divigin', 'music', 'gardening', 'woodworking', 'karaoke'], 'TV show': ['The Sopranos', 'Fargo', 'The Wire', 'Stranger Things', 'Friends'], 'fruit': ['banana', 'grape', 'cherry', 'tangerine', 'kiwi'], 'music': ['rap', 'dance music', 'metal', 'classical', 'hip-hop'], 'dessert': ['cannoli', 'fortune cookie', 'rice pudding', 'popover', 'Neapolitan ice cream'], 'sport': ['baseball', 'badminton', 'Tennis', 'hockey', 'skiing'], 'genre': ['comedy', 'crime', 'action', 'historical fiction', 'romance'], 'interest': ['to play board games', 'to sing', 'to watch sports', 'to watch tv shows', 'to play sports'], 'movie': ['Joker', 'Pulp fiction', 'Goodfellas', 'The Shining', 'The Shawshank Redemption'], 'book': ['To Kill a Mockingbird', 'Lord of the Flies', 'The Da Vinci Code', 'The Fault in our Stars', 'The Hunger Games'], 'color': ['yellow', 'purple', 'green', 'teal', 'red']}\n"
     ]
    }
   ],
   "source": [
    "#Extract a number of favorite noun's for each topic for easy access\n",
    "topic_favorites = {}\n",
    "select_n = 5\n",
    "\n",
    "for topic in memory_topics:\n",
    "    topic_list = like_memory.loc[like_memory['topic'] == topic]\n",
    "    topic_list = topic_list.sort_values(by=['sentiment'], ascending=False)\n",
    "    temp_l = []\n",
    "    for i in range(select_n):\n",
    "        temp_l.append(topic_list.subject.iloc[i])#,topic_list.sentiment.iloc[i]))\n",
    "    topic_favorites[topic] = temp_l\n",
    "  \n",
    "print(topic_favorites)\n",
    "#memory_topics = topic_favorites.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'animal': ['beaver', 'ferret', 'duck', 'lion', 'dolphin'], 'food': ['steak', 'pizza', 'hamburger', 'french fries', 'ratatouille'], 'hobby': ['pottery', 'art', 'playing darts', 'sewing', 'karaoke'], 'TV show': ['Hunters', 'Better Call Saul', 'Game of Thrones', 'The Walking Dead', 'The Mandalorian'], 'fruit': ['coconut', 'citrus', 'citron', 'papaya', 'blueberry'], 'music': ['reggae', 'jazz', 'rock', 'EDM', 'house'], 'dessert': ['cookie', 'strudel', 'chocolate bar', 'Danish pastry', 'vanilla cream pie'], 'sport': ['golf', 'american football', 'Soccer', 'volleyball', 'boxing'], 'genre': ['science fiction', 'fantasy', 'mystery', 'historical', 'horror'], 'interest': ['to draw', 'to listen to music', 'to read books', 'to play games', 'to play sports'], 'movie': ['Frozen', '1917', 'The Dark Knight', 'Avengers', 'Parasite'], 'book': ['Les Mis√©rables', 'Pride and Prejudice', 'Gone with the Wind', 'The Chronicles of Narnia', 'Twilight'], 'color': ['turquoise', 'black', 'blue', 'white', 'grey']}\n"
     ]
    }
   ],
   "source": [
    "topic_dislike = {}\n",
    "for topic in memory_topics:\n",
    "    topic_list = like_memory.loc[like_memory['topic'] == topic]\n",
    "    topic_list = topic_list.sort_values(by=['sentiment'])\n",
    "    temp_l = []\n",
    "    for i in range(select_n):\n",
    "        temp_l.append(topic_list.subject.iloc[i])#,topic_list.sentiment.iloc[i]))\n",
    "    topic_dislike[topic] = temp_l\n",
    "  \n",
    "print(topic_dislike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default values\n",
    "sentiment_opt_pos = [\"like\", \"likes\", \"love\", \"loves\"]\n",
    "sentiment_opt_neg = [\"dislikes\", \"dislike\", \"hate\", \"hates\"]\n",
    "sentiment_opt = sentiment_opt_pos + sentiment_opt_neg\n",
    "wildcards = {\"noun\": '<noun>', \"sentiment\":'<sentiment>', \"topic\" : \"<topic>\",\n",
    "             \"agent_sentiment\" : '<sentiment_1>', \"noun_1\" : '<noun_1>', \"noun_2\" : '<noun_2>',\n",
    "             \"noun_3\" : '<noun_3>'}\n",
    "question_sentiment = \"like\" #default sentiment is to ask if you like something\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_subject_sentiment(key):\n",
    "    key = key.lower()\n",
    "    ans_sent = None\n",
    "\n",
    "    temp_l = like_memory.loc[like_memory['subject'] == key]\n",
    "\n",
    "    if len(temp_l) > 0:\n",
    "        ans_sent = temp_l.sentiment.iloc[0]\n",
    "        #print(temp_l) #if subject listed under multiple \n",
    "    #print(key, ans_sent)\n",
    "    return ans_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input subject to find topic: Apple -> Food/Fruit\n",
    "def fetch_noun_relations(noun):\n",
    "    temp_noun_set = set()\n",
    "    query_noun = noun\n",
    "    api_path = 'http://api.conceptnet.io/query?start=/c/en/' + query_noun + '&rel=/r/IsA'\n",
    "    obj = requests.get(api_path).json()\n",
    "    #print(obj['edges'][0])\n",
    "    \n",
    "    #outer for traverses the edges, inner for traverses the content in the 'end' tag\n",
    "    for j in range(len(obj['edges'])):\n",
    "        #print(\"Description:\", obj['edges'][j]['surfaceText'])\n",
    "        for i in obj['edges'][j]['end']:\n",
    "            #if i == 'label':\n",
    "             #   print(\"Label:\", obj['edges'][j]['end'][i]) \n",
    "            #elif i == 'sense_label':\n",
    "             #   print(\"Sense_label:\", obj['edges'][j]['end'][i])\n",
    "            temp_string = obj['edges'][j]['end'][i]\n",
    "            text = nlp(temp_string)\n",
    "              \n",
    "            for token in text:\n",
    "                tag = nltk.pos_tag([token.text])\n",
    "                if token.pos_ == \"NOUN\" or tag == \"NN\" or tag == 'NNS':\n",
    "                    temp_noun_set.add(token.text)\n",
    "       \n",
    "    #print(temp_noun_set)\n",
    "    return temp_noun_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input noun-> find noun's IsA relations e.g Apple is a fruit -> compare IsA relations with existing topics.\n",
    "def check_noun_topic_exist_memory(noun):\n",
    "    temp_noun_set = fetch_noun_relations(noun)\n",
    "    \n",
    "    union_topics = []\n",
    "    for topic in memory_topics:\n",
    "        for item in temp_noun_set:\n",
    "            if item == topic:\n",
    "                union_topics.append(item)\n",
    "    return union_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if noun is a known subject in memory\n",
    "def is_noun_existing_subject(noun):\n",
    "    temp_l = like_memory.loc[like_memory['subject'] == noun]\n",
    "    if len(temp_l) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if noun is a known topic in memory\n",
    "def is_noun_existing_topic(noun):\n",
    "    return noun in memory_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_calc(X,Y):\n",
    "    X = X.lower() #input(q).lower() \n",
    "    Y = Y.lower() #input(form_input).lower() \n",
    "\n",
    "    # tokenization \n",
    "    X_list = word_tokenize(X)  \n",
    "    Y_list = word_tokenize(Y) \n",
    "\n",
    "    # sw contains the list of stopwords \n",
    "    sw = stopwords.words('english')  \n",
    "    l1 =[];l2 =[] \n",
    "\n",
    "    # remove stop words from string \n",
    "    X_set = {w for w in X_list}# if not w in sw}  \n",
    "    Y_set = {w for w in Y_list} #if not w in sw} \n",
    "\n",
    "    # form a set containing keywords of both strings  \n",
    "    rvector = X_set.union(Y_set)  \n",
    "    for w in rvector: \n",
    "        if w in X_set: l1.append(1) # create a vector \n",
    "        else: l1.append(0) \n",
    "        if w in Y_set: l2.append(1) \n",
    "        else: l2.append(0) \n",
    "    c = 0\n",
    "\n",
    "    # cosine formula  \n",
    "    for i in range(len(rvector)): \n",
    "            c+= l1[i]*l2[i] \n",
    "    cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process the user input \n",
    "def process_user_input(user_input):\n",
    "    extracted_nouns = []\n",
    "    form_input = user_input\n",
    "    global question_sentiment\n",
    "    question_sentiment = \"like\"\n",
    "    global like_memory\n",
    "    noun = None\n",
    "    sentiment_exist = False\n",
    "    noun_topics = []\n",
    "    text = nlp(user_input)\n",
    "    \n",
    "    for token in text:\n",
    "        if token.text in sentiment_opt:\n",
    "            question_sentiment = token.text\n",
    "            sentiment_exist = True\n",
    "            \n",
    "        tag = nltk.pos_tag([token.text])\n",
    "        if token.pos_ == \"NOUN\" or tag[0][1] == \"NN\" or tag[0][1] == 'NNS':\n",
    "            extracted_nouns.append(token.lemma_)\n",
    "            extracted_nouns.append(token.text) \n",
    "    for n in extracted_nouns:\n",
    "        if is_noun_existing_topic(n):\n",
    "            noun_topics = [noun]\n",
    "            noun = n\n",
    "            break\n",
    "            \n",
    "        noun_topics = check_noun_topic_exist_memory(n)\n",
    "        if is_noun_existing_subject(n):\n",
    "            noun = n\n",
    "            break\n",
    "        elif len(noun_topics) >0:\n",
    "            noun = n\n",
    "            #if the noun is not a known subject (Apple, Soccer, Pasta) then add it with random sentiment  \n",
    "            noun_sent = np.random.random(1)\n",
    "            for topic in noun_topics:\n",
    "                like_memory = like_memory.append({'subject' : noun , 'topic' : topic, 'sentiment' : noun_sent} , ignore_index=True)\n",
    "            break\n",
    "    \n",
    "    if noun != None:\n",
    "        if is_noun_existing_topic(noun):\n",
    "            noun_topics = [noun]\n",
    "            form_input = form_input.replace(noun, wildcards[\"topic\"])\n",
    "        else:\n",
    "            form_input = form_input.replace(noun, wildcards[\"noun\"])\n",
    "    if sentiment_exist:\n",
    "        form_input = form_input.replace(question_sentiment, wildcards['sentiment'])\n",
    "\n",
    "    #print(user_input, form_input, noun)\n",
    "    return form_input, noun, noun_topics, user_input, extracted_nouns, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_question_n_answer_retrieval(user_input):\n",
    "    max_sim = 0\n",
    "    max_sim_q = None\n",
    "    answer_id = 0\n",
    "   \n",
    "    for i in range(len(retrieval_q)):\n",
    "        q = retrieval_q.question[i]\n",
    "        qid = retrieval_q.answer_id[i]\n",
    "        \n",
    "        cosine = similarity_calc(q,user_input)\n",
    "\n",
    "        if int(cosine) == 1:\n",
    "            max_sim_q = q\n",
    "            answer_id = qid\n",
    "            max_sim = cosine\n",
    "            break\n",
    "        elif cosine > max_sim:\n",
    "            max_sim = cosine\n",
    "            max_sim_q = q\n",
    "            answer_id = qid\n",
    "            \n",
    "    fetch_answer = retrieval_a.loc[retrieval_a['answer_id'] == answer_id]\n",
    "    answer = fetch_answer.sample().iloc[0].answer\n",
    "    #print(max_sim_q, max_sim)\n",
    "    return answer, answer_id, max_sim_q, max_sim\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find a suitable question template and return it\n",
    "def find_question_template(processed_text_input):\n",
    "    max_sim = 0\n",
    "    max_sim_q = None\n",
    "    answer_id = 0\n",
    "    sent_is_positive = False\n",
    "    if question_sentiment in sentiment_opt_pos:\n",
    "        sent_is_positive = True\n",
    "    for i in range(len(template_q)):\n",
    "        if sent_is_positive == False and template_q.default_positive[i] == 1:\n",
    "            continue\n",
    "        q = template_q.question[i]\n",
    "        qid = template_q.answer_id[i]\n",
    "        \n",
    "        cosine = similarity_calc(q,processed_text_input)\n",
    "\n",
    "        if int(cosine) == 1:\n",
    "            max_sim_q = q\n",
    "            answer_id = qid\n",
    "            max_sim = cosine\n",
    "            break\n",
    "        elif cosine > max_sim:\n",
    "            max_sim = cosine\n",
    "            max_sim_q = q\n",
    "            answer_id = qid\n",
    "        \n",
    "    #print(max_sim_q, max_sim)\n",
    "    return answer_id, max_sim_q, max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_answer_template(answer_id, noun, noun_topics):\n",
    "    global like_memory\n",
    "    global question_sentiment\n",
    "    fetch_answer = template_a.loc[template_a['answer_id'] == answer_id]\n",
    "    #default\n",
    "    ans_sentiment = \"like\"\n",
    "    ans_sent_val = None\n",
    "    ret_nouns = noun \n",
    "    for key in memory_topics:\n",
    "        if noun == key:\n",
    "            if question_sentiment in sentiment_opt_pos:\n",
    "                ret_nouns = topic_favorites[key]\n",
    "                ans_sent_val = 0.5\n",
    "                break\n",
    "            else:\n",
    "                ret_nouns = topic_dislike[key]\n",
    "                ans_sent_val = 0.5\n",
    "                #question_sentiment = \"dislike\"\n",
    "                if answer_id != 1:\n",
    "                    ans_sentiment = \"hate\"\n",
    "                break\n",
    "    #if the noun is not a topic (Food/Sports/...)\n",
    "    if ans_sent_val == None:\n",
    "        ans_sent_val = fetch_subject_sentiment(noun)\n",
    "        ans_sentiment = sent_float_to_text(ans_sent_val)\n",
    "\n",
    "    #the user is talking about something we don't handle in memory.\n",
    "    elif ans_sent_val == None and noun_topics == None:\n",
    "        #todo\n",
    "        pass\n",
    "\n",
    "        \n",
    "            \n",
    "    if (((ans_sentiment in sentiment_opt_pos) and (question_sentiment in sentiment_opt_pos)) \n",
    "        or ((ans_sentiment in sentiment_opt_neg) and (question_sentiment in sentiment_opt_neg))):\n",
    "        fetch_answer = fetch_answer.loc[fetch_answer['same_sentiment'] == 1]\n",
    "    else:\n",
    "        fetch_answer = fetch_answer.loc[fetch_answer['same_sentiment'] == 0]\n",
    "        \n",
    "    #fetch_answer = template_a.loc[template_a['answer_id'] == answer_id ]\n",
    "    return fetch_answer, ret_nouns, ans_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_float_to_text(sentiment):\n",
    "    ret_sentiment = \"love\"\n",
    "    if sentiment < 0.1:\n",
    "        ret_sentiment = \"hate\"\n",
    "    elif sentiment < 0.5:\n",
    "        ret_sentiment = \"dislike\"\n",
    "    elif sentiment < 0.9:\n",
    "        ret_sentiment = \"like\"\n",
    "        \n",
    "    return ret_sentiment\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_agent_output(answer_template, noun, nouns, noun_topics, answer_sentiment):\n",
    "    agent_output = answer_template.answer\n",
    "    temp_nouns = nouns\n",
    "    #print(agent_output, nouns, noun_topics, (nouns))\n",
    "    if answer_template.fetch_count > 0 and noun_topics != None and len(noun_topics) >0:\n",
    "        #print(noun_topics)\n",
    "        if question_sentiment in sentiment_opt_pos:\n",
    "            temp_nouns = topic_favorites[noun_topics[0]]\n",
    "        elif question_sentiment in sentiment_opt_neg:\n",
    "            temp_nouns = topic_dislike[noun_topics[0]]\n",
    "            \n",
    "    #replace nouns\n",
    "    for i in range(1,answer_template.fetch_count+1):\n",
    "        temp = \"noun_\"+str(i)\n",
    "        agent_output = agent_output.replace(wildcards[temp], temp_nouns[i-1])\n",
    "    \n",
    "    if answer_template.use_noun:\n",
    "        agent_output = agent_output.replace(wildcards[\"noun\"], noun)\n",
    "    if answer_template.use_sentiment:\n",
    "        agent_output = agent_output.replace(wildcards[\"sentiment\"], question_sentiment)\n",
    "    agent_output = agent_output.replace(wildcards[\"agent_sentiment\"], answer_sentiment)\n",
    "    #print(agent_output)\n",
    "    return agent_output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 Model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '124M'\n",
    "run_name =\"run_10\"\n",
    "#gpt2.download_gpt2(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoint\\run_10\\model-200\n",
      "INFO:tensorflow:Restoring parameters from checkpoint\\run_10\\model-200\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, run_name=run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reply(user_question, num_answers=1):\n",
    "    text_input = \"<|startoftext|>\" + user_question\n",
    "    gen_ans =gpt2.generate(sess,\n",
    "                  run_name=run_name,\n",
    "                  length=40,\n",
    "                  temperature=1,\n",
    "                  prefix=text_input,\n",
    "                  truncate=\"<|endoftext|>\",\n",
    "                  include_prefix=False,\n",
    "                  nsamples=num_answers,\n",
    "                  batch_size=num_answers,\n",
    "                  top_p=0.9,\n",
    "                  return_as_list=True\n",
    "                  )\n",
    "    return gen_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interact with agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> What do you like?\n",
      "\n",
      " What do you like?\n",
      " I like travel.\n",
      "> What more do you like ?\n",
      "\n",
      " What more do you like ?\n",
      " I like travel.\n",
      "> Where do you like to travel?\n",
      "\n",
      " Where do you like to travel?\n",
      " I have been to a few countries in Europe which I really enjoyed, hoping to go back soon.\n",
      "> What tv shows do you like?\n",
      "\n",
      " What tv shows do you like?\n",
      " NCIS, Modern Family.\n",
      "> Do you like apples?\n",
      "\n",
      " Do you like apples?\n",
      "No, I don't like apple but I like eggs.\n",
      "> What fruits do you like?\n",
      "\n",
      " What fruits do you like?\n",
      "I like banana.\n",
      "> Do you like any other fruits?\n",
      "\n",
      " Do you like any other fruits?\n",
      "I like banana the most! But I also like grape.\n",
      "> What food do you like?\n",
      "\n",
      " What food do you like?\n",
      "I like eggs and rice.\n",
      "> What do you think about rice?\n",
      "\n",
      " What do you think about rice?\n",
      "I like it!\n",
      "> What food do you dislike\n",
      "\n",
      " What food do you dislike\n",
      "I dislike steak and pizza.\n",
      "> what do you think about pizza?\n",
      "\n",
      " what do you think about pizza?\n",
      "Hm...I don't really like pizza that much.\n",
      "> Why do you dislike pizza?\n",
      "\n",
      " Why do you dislike pizza?\n",
      "I do dislike pizza. I also dislike steak.\n",
      "> What animals do you like?\n",
      "\n",
      " What animals do you like?\n",
      "I like tiger the most! But I also like sheep.\n",
      "> Do you like eggs?\n",
      "\n",
      " Do you like eggs?\n",
      "Yes, I like it!\n",
      "> Do you like tigers?\n",
      "\n",
      " Do you like tigers?\n",
      "Yes, I like it!\n",
      "> Do you like bananas?\n",
      "\n",
      " Do you like bananas?\n",
      "Yes, I like it!\n",
      "> Do you like bananas?\n",
      "\n",
      " Do you like bananas?\n",
      "Yes, I like banana.\n",
      "> Do you like any movies?\n",
      "\n",
      " Do you like any movies?\n",
      "I like Joker.\n",
      "> Do you like any books?\n",
      "\n",
      " Do you like any books?\n",
      "I like To Kill a Mockingbird and Lord of the Flies.\n",
      "> What books do you usually read?\n",
      "\n",
      " What books do you usually read?\n",
      "I like To Kill a Mockingbird, Lord of the Flies and The Da Vinci Code.\n",
      "> Do you like any sports?\n",
      "\n",
      " Do you like any sports?\n",
      "I like baseball.\n",
      "> Do you hate any sports?\n",
      "\n",
      " Do you hate any sports?\n",
      "I hate golf, american football and Soccer.\n",
      "> Do you have a favorite dessert?\n",
      "\n",
      " Do you have a favorite dessert?\n",
      "I like cannoli the most.\n",
      "> Any other favorite desserts?\n",
      "\n",
      " Any other favorite desserts?\n",
      "I think I like cannoli the most.\n",
      "> What is your favorite color?\n",
      "\n",
      " What is your favorite color?\n",
      "I'm not sure but I really like yellow a lot.\n",
      "> Do you have a favorite color?\n",
      "\n",
      " Do you have a favorite color?\n",
      "I think I like yellow the most.\n",
      "> q\n"
     ]
    }
   ],
   "source": [
    "input_sentence = ''\n",
    "while(1):\n",
    "    try:\n",
    "        # Get input sentence\n",
    "        input_sentence = input('> ')\n",
    "        # Check if it is quit case\n",
    "        if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "\n",
    "        processed_text_input, user_noun, noun_topics  = process_user_input(input_sentence)[0:3]\n",
    "        answer_id = find_question_template(processed_text_input)[0]\n",
    "        #print(answer_id)\n",
    "        if user_noun != None:\n",
    "\n",
    "            answer, nouns, answer_sentiment = fetch_answer_template(answer_id, user_noun, noun_topics)\n",
    "            #print('\\n',input_sentence)#, question_sentiment)\n",
    "            print(process_agent_output(answer.sample().iloc[0], user_noun, nouns,noun_topics, answer_sentiment))\n",
    "        else:\n",
    "            ans = generate_reply(input_sentence)\n",
    "            #print('\\n',input_sentence)#, question_sentiment)\n",
    "            print(ans[0])\n",
    "    except KeyError:\n",
    "        print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trash below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you have any movies that you hate? Do you have any <topic>s that you <sentiment>? movie\n",
      "do you <sentiment> any type of <topic>? 0.7627700713964739\n",
      "\n",
      " Do you have any movies that you hate?\n",
      "['movie']\n",
      "I hate Joker the most! But I also hate Frozen.\n"
     ]
    }
   ],
   "source": [
    "#fetch_subject_sentiment(\"berry\")\n",
    "#print(fetch_noun_relations(\"candy\"))\n",
    "#print(check_noun_topic_exist_memory(\"sugar\") )\n",
    "\n",
    "user_input = \"Do you have any movies that you hate?\"\n",
    "processed_text_input, user_noun, noun_topics  = process_user_input(user_input)[0:3]\n",
    "#print(processed_text_input, user_noun, noun_topics)\n",
    "answer_id = find_question_template(processed_text_input)[0]\n",
    "#print(answer_id)\n",
    "if user_noun != None:\n",
    "    \n",
    "    answer, nouns, answer_sentiment = fetch_answer_template(answer_id, user_noun, noun_topics)\n",
    "    print('\\n',user_input)#, question_sentiment)\n",
    "    print(process_agent_output(answer.sample().iloc[0], user_noun, nouns,noun_topics, answer_sentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' I like to go to a movie night and not worry about getting in the door. I like to go running around.']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_reply(\"What do you like to do on the weekend?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I -PRON-\n",
      "likes like\n",
      "bananas banana\n",
      ", ,\n",
      "do do\n",
      "you -PRON-\n",
      "like like\n",
      "to to\n",
      "eat eat\n",
      "banana banana\n",
      "? ?\n"
     ]
    }
   ],
   "source": [
    "fetch_noun_relations(\"nourishment\")\n",
    "text = nlp(\"I likes bananas, do you like to eat banana?\")\n",
    "for token in text:\n",
    "    print(token.text, token.lemma_)\n",
    "    #if token.pos_ == \"NOUN\":\n",
    "        #temp_noun_set.add(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for topic in memory_topics:\n",
    "    topic_list = like_memory.loc[like_memory['topic'] == topic]\n",
    "    \n",
    "    divisor = len(topic_list)\n",
    "    for i in range(divisor):\n",
    "        noun = topic_list.subject.iloc[i]\n",
    "        noun_topics = check_noun_topic_exist_memory(noun)\n",
    "        \n",
    "        if len(noun_topics) >0:\n",
    "            #if the noun is not a known subject (Apple, Soccer, Pasta) then add it with random sentiment  \n",
    "            noun_sent = np.random.random(1)\n",
    "            for topic in noun_topics:\n",
    "                df = df.append({'sentiment' : noun_sent, 'topic' : topic, 'subject' : noun } , ignore_index=True)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "almond\n",
      "almond\n",
      "anchovy\n",
      "anise\n",
      "appetizer\n",
      "apple\n",
      "apple\n",
      "apricot\n",
      "apricot\n",
      "artichoke\n",
      "asparagus\n",
      "aspic\n",
      "avocado\n",
      "avocado\n",
      "bacon\n",
      "bagel\n",
      "banana\n",
      "banana\n",
      "barbecue\n",
      "barley\n",
      "basil\n",
      "batter\n",
      "beef\n",
      "beet\n",
      "berry\n",
      "berry\n",
      "biscuit\n",
      "bitter\n",
      "blackberry\n",
      "blackberry\n",
      "blueberry\n",
      "blueberry\n",
      "bowl\n",
      "boysenberry\n",
      "bran\n",
      "bread\n",
      "breadfruit\n",
      "breadfruit\n",
      "breakfast\n",
      "brisket\n",
      "broccoli\n",
      "brownie\n",
      "brunch\n",
      "buckwheat\n",
      "burrito\n",
      "butter\n",
      "cake\n",
      "cake\n",
      "candy\n",
      "caramel\n",
      "carrot\n",
      "cashew\n",
      "casserole\n",
      "cauliflower\n",
      "caviar\n",
      "celery\n",
      "cereal\n",
      "chard\n",
      "cheddar\n",
      "cheese\n",
      "cheesecake\n",
      "chef\n",
      "cherry\n",
      "cherry\n",
      "chew\n",
      "chicken\n",
      "chili\n",
      "chips\n",
      "chives\n",
      "chocolate\n",
      "chow\n",
      "chutney\n",
      "cinnamon\n",
      "citron\n",
      "citrus\n",
      "citrus\n",
      "clam\n",
      "cobbler\n",
      "coconut\n",
      "coconut\n",
      "cod\n",
      "coffee\n",
      "coleslaw\n",
      "cook\n",
      "cookie\n",
      "corn\n",
      "cornmeal\n",
      "crab\n",
      "cranberry\n",
      "cranberry\n",
      "cream\n",
      "cucumber\n",
      "cucumber\n",
      "cuisine\n",
      "cupcake\n",
      "curry\n",
      "custard\n",
      "dairy\n",
      "dessert\n",
      "diet\n",
      "dill\n",
      "dinner\n",
      "dip\n",
      "dish\n",
      "dough\n",
      "doughnut\n",
      "dressing\n",
      "drink\n",
      "durian\n",
      "durian\n",
      "egg\n",
      "eggplant\n",
      "eggplant\n",
      "elderberry\n",
      "elderberry\n",
      "entree\n",
      "fat\n",
      "feed\n",
      "fennel\n",
      "fig\n",
      "fig\n",
      "fillet\n",
      "fish\n",
      "flan\n",
      "flour\n",
      "fritter\n",
      "frosting\n",
      "fruit\n",
      "garlic\n",
      "gastronomy\n",
      "gelatin\n",
      "ginger\n",
      "gingerbread\n",
      "grain\n",
      "granola\n",
      "grape\n",
      "grape\n",
      "grapefruit\n",
      "gravy\n",
      "greens\n",
      "guacamole\n",
      "guava\n",
      "guava\n",
      "gyro\n",
      "halibut\n",
      "ham\n",
      "hamburger\n",
      "hash\n",
      "hazelnut\n",
      "hazelnut\n",
      "honey\n",
      "honeydew\n",
      "horseradish\n",
      "hummus\n",
      "ice\n",
      "ice\n",
      "jackfruit\n",
      "jackfruit\n",
      "jam\n",
      "jelly\n",
      "jimmies\n",
      "juice\n",
      "juice\n",
      "julienne\n",
      "kale\n",
      "kebab\n",
      "ketchup\n",
      "kitchen\n",
      "kiwi\n",
      "kiwi\n",
      "kohlrabi\n",
      "kumquat\n",
      "lamb\n",
      "lard\n",
      "lasagna\n",
      "lemon\n",
      "lemon\n",
      "lemonade\n",
      "lemonade\n",
      "lettuce\n",
      "licorice\n",
      "lime\n",
      "lime\n",
      "liver\n",
      "loaf\n",
      "lobster\n",
      "lollipop\n",
      "loquat\n",
      "loquat\n",
      "lox\n",
      "lunch\n",
      "lychee\n",
      "macaroni\n",
      "macaroon\n",
      "mango\n",
      "mango\n",
      "margarine\n",
      "marmalade\n",
      "marshmallow\n",
      "mayonnaise\n",
      "meat\n",
      "meatball\n",
      "melon\n",
      "melon\n",
      "menu\n",
      "meringue\n",
      "micronutrient\n",
      "milk\n",
      "milkshake\n",
      "millet\n",
      "mincemeat\n",
      "mint\n",
      "molasses\n",
      "mozzarella\n",
      "muffin\n",
      "mushroom\n",
      "mustard\n",
      "nectar\n",
      "nectar\n",
      "nectarine\n",
      "nectarine\n",
      "noodles\n",
      "nosh\n",
      "nut\n",
      "nutmeg\n",
      "oatmeal\n",
      "okra\n",
      "olive\n",
      "olive\n",
      "omelet\n",
      "onion\n",
      "orange\n",
      "orange\n",
      "oyster\n",
      "pan\n",
      "pancake\n",
      "papaya\n",
      "papaya\n",
      "parsley\n",
      "parsnip\n",
      "pasta\n",
      "pastry\n",
      "pate\n",
      "patty\n",
      "pea\n",
      "peach\n",
      "peach\n",
      "peanut\n",
      "pear\n",
      "pear\n",
      "pecan\n",
      "pecan\n",
      "pepper\n",
      "pepper\n",
      "pepperoni\n",
      "persimmon\n",
      "persimmon\n",
      "pickle\n",
      "picnic\n",
      "pie\n",
      "pie\n",
      "pilaf\n",
      "pineapple\n",
      "pineapple\n",
      "pizza\n",
      "plate\n",
      "plum\n",
      "plum\n",
      "pomegranate\n",
      "pomegranate\n",
      "pomelo\n",
      "pop\n",
      "popcorn\n",
      "pork\n",
      "potato\n",
      "pretzel\n",
      "prune\n",
      "prune\n",
      "pudding\n",
      "pumpernickel\n",
      "pumpkin\n",
      "pumpkin\n",
      "punch\n",
      "quiche\n",
      "radish\n",
      "raisin\n",
      "raisin\n",
      "raspberry\n",
      "raspberry\n",
      "ravioli\n",
      "relish\n",
      "rice\n",
      "roast\n",
      "rosemary\n",
      "rye\n",
      "saffron\n",
      "sage\n",
      "salad\n",
      "salami\n",
      "salmon\n",
      "salsa\n",
      "salt\n",
      "sandwich\n",
      "sauce\n",
      "sauerkraut\n",
      "sausage\n",
      "savory\n",
      "sherbet\n",
      "sherbet\n",
      "snack\n",
      "sole\n",
      "sorbet\n",
      "sorbet\n",
      "sorghum\n",
      "sorrel\n",
      "soup\n",
      "sour\n",
      "soy\n",
      "spaghetti\n",
      "spareribs\n",
      "spinach\n",
      "sprinkles\n",
      "squash\n",
      "squash\n",
      "squid\n",
      "steak\n",
      "stew\n",
      "strawberry\n",
      "strawberry\n",
      "strudel\n",
      "succotash\n",
      "suet\n",
      "sugar\n",
      "sundae\n",
      "supper\n",
      "sushi\n",
      "sweet\n",
      "syrup\n",
      "taco\n",
      "tamale\n",
      "tangerine\n",
      "tapioca\n",
      "taro\n",
      "tarragon\n",
      "tart\n",
      "tea\n",
      "teriyaki\n",
      "thyme\n",
      "toast\n",
      "toffee\n",
      "tomatillo\n",
      "tomato\n",
      "tomato\n",
      "torte\n",
      "tortilla\n",
      "tuna\n",
      "turkey\n",
      "turmeric\n",
      "turnip\n",
      "vanilla\n",
      "veal\n",
      "vegetable\n",
      "venison\n",
      "vinegar\n",
      "vitamin\n",
      "wafer\n",
      "waffle\n",
      "walnut\n",
      "walnut\n",
      "wasabi\n",
      "water\n",
      "watercress\n",
      "watermelon\n",
      "watermelon\n",
      "wheat\n",
      "whey\n",
      "yam\n",
      "yeast\n",
      "yogurt\n",
      "yolk\n",
      "zucchini\n",
      "apple\n",
      "apple\n",
      "apricot\n",
      "apricot\n",
      "avocado\n",
      "avocado\n",
      "banana\n",
      "banana\n",
      "berry\n",
      "berry\n",
      "blackberry\n",
      "blackberry\n",
      "blueberry\n",
      "blueberry\n",
      "boysenberry\n",
      "breadfruit\n",
      "breadfruit\n",
      "cherry\n",
      "cherry\n",
      "citron\n",
      "citrus\n",
      "citrus\n",
      "coconut\n",
      "coconut\n",
      "cranberry\n",
      "cranberry\n",
      "durian\n",
      "durian\n",
      "elderberry\n",
      "elderberry\n",
      "fig\n",
      "fig\n",
      "grape\n",
      "grape\n",
      "grapefruit\n",
      "guava\n",
      "guava\n",
      "honeydew\n",
      "jackfruit\n",
      "jackfruit\n",
      "kiwi\n",
      "kiwi\n",
      "kumquat\n",
      "lemon\n",
      "lemon\n",
      "lime\n",
      "lime\n",
      "lingonberry\n",
      "loquat\n",
      "loquat\n",
      "lychee\n",
      "mango\n",
      "mango\n",
      "melon\n",
      "melon\n",
      "mulberry\n",
      "mulberry\n",
      "nectarine\n",
      "nectarine\n",
      "orange\n",
      "orange\n",
      "papaya\n",
      "papaya\n",
      "peach\n",
      "peach\n",
      "pear\n",
      "pear\n",
      "persimmon\n",
      "persimmon\n",
      "pineapple\n",
      "pineapple\n",
      "plantain\n",
      "plum\n",
      "plum\n",
      "pluot\n",
      "pomegranate\n",
      "pomegranate\n",
      "pomelo\n",
      "prune\n",
      "prune\n",
      "quince\n",
      "quince\n",
      "raisin\n",
      "raisin\n",
      "raspberry\n",
      "raspberry\n",
      "strawberry\n",
      "strawberry\n",
      "tangelo\n",
      "tangelo\n",
      "tangerine\n",
      "watermelon\n",
      "watermelon\n",
      "ambrosia\n",
      "baklava\n",
      "biscotti\n",
      "brownie\n",
      "butterscotch\n",
      "cake\n",
      "cake\n",
      "cannoli\n",
      "cheesecake\n",
      "churro\n",
      "cobbler\n",
      "cookie\n",
      "cupcake\n",
      "custard\n",
      "dessert\n",
      "doughnut\n",
      "eclair\n",
      "flan\n",
      "fritter\n",
      "frosting\n",
      "fudge\n",
      "gelatin\n",
      "gingerbread\n",
      "honey\n",
      "jam\n",
      "jelly\n",
      "jellyroll\n",
      "macaroon\n",
      "marshmallow\n",
      "meringue\n",
      "milkshake\n",
      "molasses\n",
      "mousse\n",
      "muffin\n",
      "nougat\n",
      "parfait\n",
      "parfait\n",
      "pastry\n",
      "pie\n",
      "pie\n",
      "popover\n",
      "praline\n",
      "pudding\n",
      "scone\n",
      "sherbet\n",
      "sherbet\n",
      "shortbread\n",
      "sorbet\n",
      "sorbet\n",
      "souffle\n",
      "spumoni\n",
      "strudel\n",
      "sugar\n",
      "sundae\n",
      "tart\n",
      "toffee\n",
      "torte\n",
      "trifle\n",
      "truffle\n",
      "turnover\n",
      "waffle\n"
     ]
    }
   ],
   "source": [
    "for topic in memory_topics:\n",
    "    topic_list = df.loc[like_memory['topic'] == topic]\n",
    "    \n",
    "    divisor = len(topic_list)\n",
    "    for i in range(divisor):\n",
    "        noun = topic_list.subject.iloc[i]\n",
    "        print(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'data/memory_structure_copy.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I like a lot of genres, although I have been really into contemporary classical.', 5.0, 'What kind of music do you like to listen to?', 0.8366600265340756)\n"
     ]
    }
   ],
   "source": [
    "print(find_question_n_answer_retrieval(\"do you like to listen to music?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
